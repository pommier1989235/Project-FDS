{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"covid_early_stage_symptoms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].loc[df['gender'] == 'male'] = 0\n",
    "df['gender'].loc[df['gender'] == 'female'] = 1\n",
    "\n",
    "df['age_year'] = df['age_year'].apply(lambda x: 0 if x < 40 else 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('SARS-CoV-2 Positive').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SARS-CoV-2 Positive'], axis = 1, inplace = False).to_numpy(dtype = float)\n",
    "print(X[X[:,1] > 1])\n",
    "\n",
    "y = df['SARS-CoV-2 Positive'].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "Z = preprocessing.StandardScaler().fit_transform(X) # normalize\n",
    "\n",
    "#Do ACP\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = PCA(n_components=Z.shape[1])\n",
    "pca = PCA(n_components=Z.shape[1])\n",
    "A = pca.fit_transform(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = np.hstack([np.ones((A.shape[0], 1)), A])\n",
    "x_train,x_test,y_train,y_test=train_test_split(A,y,random_state=4,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):    \n",
    "    g=1/(1+np.exp(-x))\n",
    "    return g\n",
    "\n",
    "def gradient_descent(theta, features, target, lr, num_steps):\n",
    "    log_likelihood_history = np.zeros(num_steps)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # compute and store the log_likelihood value\n",
    "        hypothesis = sigmoid(theta.dot(features.T))\n",
    "        log_likelihood_history[step] = np.sum(target*np.log(hypothesis)+(1-target)*np.log(1-hypothesis))/features.shape[0]\n",
    "        #update theta to do the gradient descent \n",
    "        theta -= lr * (-np.sum((target - sigmoid(theta.dot(features.T)))[:,np.newaxis] * features, axis=0) / features.shape[0])\n",
    "\n",
    "    return theta, log_likelihood_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize theta0\n",
    "theta0 = np.ones(x_train.shape[1])\n",
    "\n",
    "# Run Gradient Ascent method\n",
    "n_iter=3000\n",
    "theta_final, log_l_history = gradient_descent(theta0, x_train, y_train, lr=0.5, num_steps=n_iter)\n",
    "print(theta_final)\n",
    "\n",
    "fig,ax = plt.subplots(num=2)\n",
    "\n",
    "ax.set_ylabel('l(Theta)')\n",
    "ax.set_xlabel('Iterations')\n",
    "_=ax.plot(range(len(log_l_history)),log_l_history,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vector to plot decision boundary\n",
    "x1_vec = np.linspace(x_train[:,0].min(),x_train[:,1].max(),2)\n",
    "\n",
    "# Plot raw data\n",
    "sns.scatterplot(x=x_train[:,0], y=x_train[:,1], hue=y_train)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.plot(x1_vec,(-x1_vec*theta_final[1]-theta_final[0])/theta_final[2], color=\"red\")\n",
    "plt.ylim(x_train[:,1].min()-1,x_train[:,1].max()+1)\n",
    "# Save the theta_final value for later comparisons\n",
    "theta_GA = theta_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(theta, X, y):\n",
    "\n",
    "    predictions = np.where(sigmoid(theta.dot(X.T)) >= 0.5, 1, 0)\n",
    "    accuracy = np.sum(predictions == y)/y.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('accuracy is :', accuracy(theta_final, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with the python library LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data to LR model\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "preds = lr.predict(x_test)\n",
    "print('accuracy is',accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = preprocessing.StandardScaler().fit_transform(X) # normalize\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "A = pca.fit_transform(Z)\n",
    "\n",
    "A = np.hstack([np.ones((A.shape[0], 1)), A])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(x, degree=2):\n",
    "    # represent the vector x0 of ones\n",
    "    features = np.ones(x[:,1].shape[0])\n",
    "    #store and stack at the right the vectors x1 and x2 (with the right shape)\n",
    "    x1,x2 = x[:,1], x[:,2]\n",
    "    features = np.hstack([features.reshape(features.shape[0], 1), x1.reshape(x1.shape[0], 1)])\n",
    "    features = np.hstack([features, x2.reshape(x2.shape[0], 1)])\n",
    "\n",
    "    # for each degree (2 or 3 or more) we stack every possible combination between x1 and x2 (sum of powers = degree = i)\n",
    "    for i in range(2, degree+1):\n",
    "        for j in range(i+1) :\n",
    "            x=(x1**(i-j))*(x2**(j))\n",
    "            features = np.hstack([features, x.reshape(x.shape[0], 1)])\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_quad = new_features(A, degree=2)\n",
    "x_new_cubic = new_features(A, degree=3)\n",
    "\n",
    "#reordering output features\n",
    "temp = np.copy(x_new_quad[:, -1])\n",
    "x_new_quad[:, -1] = x_new_quad[:, -2]\n",
    "x_new_quad[:, -2] = temp\n",
    "\n",
    "temp = np.copy(x_new_cubic[:, -1])\n",
    "x_new_cubic[:, -1] = x_new_cubic[:, -2]\n",
    "x_new_cubic[:, -2] = x_new_cubic[:, -3]\n",
    "x_new_cubic[:, -3] = temp\n",
    "\n",
    "x_train, x_test ,y_train,y_test=train_test_split(A,y,random_state=4,test_size=0.2)\n",
    "x_train_quad,x_test_quad,y_train,y_test=train_test_split(x_new_quad,y,random_state=4,test_size=0.2)\n",
    "x_train_cubic,x_test_cubic,y_train,y_test=train_test_split(x_new_cubic,y,random_state=4,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize theta0, in case of quadratic features\n",
    "theta0_quad = np.zeros(x_train_quad.shape[1])\n",
    "\n",
    "theta_final_quad, log_l_history_quad = gradient_descent(theta0_quad,x_train_quad,y_train,lr=0.01,num_steps=n_iter)\n",
    "\n",
    "# Initialize theta0, in case of quadratic and cubic features\n",
    "theta0_cubic = np.zeros(x_train_cubic.shape[1])\n",
    "\n",
    "# Run Newton's method, in case of quadratic and cubic features\n",
    "theta_final_cubic, log_l_history_cubic = gradient_descent(theta0_cubic,x_train_cubic,y_train,lr=0.01,num_steps=n_iter)\n",
    "\n",
    "# check and compare with previous results\n",
    "print(theta_final_quad)\n",
    "print(theta_final_cubic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log likelihood values in the optimization iterations, in one of the two cases.\n",
    "fig,ax = plt.subplots(num=2)\n",
    "\n",
    "ax.set_ylabel('l(Theta)')\n",
    "ax.set_xlabel('Iterations')\n",
    "_=ax.plot(range(len(log_l_history_quad)),log_l_history_quad,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log likelihood values in the optimization iterations, in one of the two cases.\n",
    "fig,ax = plt.subplots(num=2)\n",
    "\n",
    "ax.set_ylabel('l(Theta)')\n",
    "ax.set_xlabel('Iterations')\n",
    "_=ax.plot(range(len(log_l_history_quad)),log_l_history_cubic,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_function(x1_vec, x2_vec, theta_final):\n",
    "    \n",
    "    x1_vec, x2_vec = np.meshgrid(x1_vec,x2_vec)\n",
    "    x1 = x1_vec\n",
    "    x2 = x2_vec\n",
    "    \n",
    "    if len(theta_final) == 6:\n",
    "        # boundary function value for features up to quadratic\n",
    "        c_0, c_1, c_2, c_3, c_4, c_5 = theta_final\n",
    "        f = c_0 + c_1*x1 + c_2*x2 + c_3*(x1**2) + c_4*(x2**2) + c_5*x1*x2\n",
    "    elif len(theta_final) == 10:\n",
    "        # boundary function value for features up to cubic\n",
    "        c_0, c_1, c_2, c_3, c_4, c_5, c_6, c_7, c_8, c_9 = theta_final\n",
    "        f = c_0 + c_1*x1 + c_2*x2 + c_3*(x1**2) + c_4*(x2**2) + c_5*x1*x2 + c_6*(x1**3) + c_7*(x2**3) + c_8*(x1**2)*x2+ c_9*x1*(x2**2)\n",
    "    else:\n",
    "        raise(\"Number of Parameters is not correct\")\n",
    "        \n",
    "    return x1_vec, x2_vec, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_vec = np.linspace(x_train_quad[:,1].min()-1,x_train[:,1].max()+1,200);\n",
    "x2_vec = np.linspace(x_train_quad[:,2].min()-1,x_train[:,2].max()+1,200);\n",
    "\n",
    "x1_vec, x2_vec, f = boundary_function(x1_vec, x2_vec, theta_final_quad)\n",
    "\n",
    "sns.scatterplot(x=x_train_quad[:,1], y=x_train_quad[:,2], hue=y_train);\n",
    "\n",
    "plt.contour(x1_vec, x2_vec, f, colors=\"red\", levels=[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_vec = np.linspace(x_train_cubic[:,1].min()-1,x_train_cubic[:,1].max()+1,200);\n",
    "x2_vec = np.linspace(x_train_cubic[:,2].min()-1,x_train_cubic[:,2].max()+1,200);\n",
    "\n",
    "x1_vec, x2_vec, f = boundary_function(x1_vec, x2_vec, theta_final_cubic)\n",
    "\n",
    "sns.scatterplot(x=x_train_cubic[:,1], y=x_train_cubic[:,2], hue=y_train);\n",
    "\n",
    "plt.contour(x1_vec, x2_vec, f, colors=\"red\", levels=[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(theta, X, y):\n",
    "\n",
    "    predictions = np.where(sigmoid(theta.dot(X.T)) >= 0.5, 1, 0)\n",
    "    accuracy = np.sum(predictions == y)/y.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('quadratic accuracy is :', accuracy(theta_final_quad, x_test_quad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('cubic accuracy is :', accuracy(theta_final_cubic, x_test_cubic, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with the python library LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data to LR model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "preds = lr.predict(x_test)\n",
    "print('accuracy is',accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliNaiveBayes():\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "  \n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.fitted = False\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.n_samples, self.n_features = x_train.shape\n",
    "        self.features_count = np.zeros((2, self.n_features))\n",
    "        for cls in [0,1]:\n",
    "            self.features_count[cls] = np.sum(x_train[y_train==cls], axis=0)\n",
    "        self.fitted = True\n",
    "        \n",
    "        \n",
    "    # P(Y)\n",
    "    def __prior(self, cls):\n",
    "        return np.sum(y_train==cls)/self.n_samples\n",
    "        \n",
    "        \n",
    "    # P(X_i | Y_i)\n",
    "    def __feature_likelihood(self, x_i, i, cls, alpha=0.1):\n",
    "        p = (self.features_count[cls,i]) / (np.sum(self.y_train==cls))\n",
    "        return (p**x_i) * ((1-p)**(1-x_i))\n",
    "    \n",
    "    \n",
    "    # P(X | Y_i)\n",
    "    def __likelihood(self, x, cls):\n",
    "        return np.prod([self.__feature_likelihood(x[i],i,cls) for i in range(self.n_features)])\n",
    "    \n",
    "    \n",
    "    # P(Y | X)\n",
    "    def __posterior(self, x):\n",
    "        total_prob = np.sum([self.__likelihood(x,cls)*self.__prior(cls) for cls in [0,1]]) \n",
    "        return self.__likelihood(x,1)*self.__prior(1)/total_prob\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        if not self.fitted:\n",
    "            raise self.NotFittedError(\"Model not fitted, please call the fit method.\")\n",
    "        return np.array([self.__posterior(sample) for sample in X_test])\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.where(self.predict_proba(X_test) < 0.5, 0, 1)\n",
    "    \n",
    "    \n",
    "    def score(self, X_test, Y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        return np.sum(predictions == Y_test) / np.sum(Y_test.shape[0])\n",
    "    \n",
    "    \n",
    "    class NotFittedError(BaseException):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=4,test_size=0.2)\n",
    "\n",
    "model = BernoulliNaiveBayes()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with sklearn\n",
    "sk_model = BernoulliNB()\n",
    "sk_model.fit(x_train, y_train)\n",
    "sk_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
